---
title: "Attitudes towards the adoption of two AI-enabled mental health tools among prospective psychotherapists"
#bibliography: "../../config/LMU_AI-Team.bib"
csl: "../../config/apa.csl"
execute:
  echo: false
  warning: false
  message: false
  cache: true
  include: false
prefer-html: true
author: "Anne-Kathrin Kleine, Eesha Kokje, Eva Lermer, & Susanne Gaube"
format: 
  docx:
    reference-doc: "../../config/template_word.docx"
  html:
    toc: true
    toc-depth: 3
---


```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
```

# Pre-registration statement 

The hypotheses were pre-registered on the Open Science Framework ([osf.io/fqdzb](https://osf.io/fqdzb)). Exploratory hypotheses are identified as such. 

# Introduction

Despite increasing efforts to develop user-friendly AI applications, they are still underutilized in clinical care [@sendak_etal20]. Factors interfering with the adoption of clinical support tools can be found on the individual, organizational, and system level [@greenhalgh_etal17; @yusof_etal08]. Initial obstacles such as a lack of innovation culture, stakeholder interests, or financial risk may impede the introduction of AI into clinical care [@shachak_etal19]. If the basic requirements are satisfied, the implementation of these tools highly relies upon the practitioner's willingness to use them. Several frameworks and theories have been applied to explain the mechanisms influencing the implementation of clinical support systems in practice [@shachak_etal19; @hsiao_chen16; @kumar_etal23; @wiljer_etal21]. The two most relevant models for individual level predictors are the Unified Theory of Acceptance and Use of Technology [UTAUT, @venkatesh22, @venkatesh_etal03, @venkatesh_etal16] and the Technology Acceptance Model [TAM, @davis89].


Multiple research studies have demonstrated the applicability of the Unified Theory of Acceptance and Use of Technology (UTAUT) and the Technology Acceptance Model (TAM) to the individual-level context of clinical support systems [e.g., @arfi_etal21; @fan_etal20; @lin_etal21; @zhai_etal21; @tran_etal21; @gado_etal22]. UTAUT and TAM consider individual attitudes towards specific technologies, such as perceived usefulness and perceived ease of use (TAM), as relevant drivers of technology acceptance and use. However, only one study has thus far examined the predictors of the intention to use AI-enabled tools in mental health care [@gado_etal22]. Results from this study, based on the UTAUT, suggest a link between perceived social norm, perceived ease of use, and perceived usefulness with psychology students' intention to use AI-enabled tools in mental health practice.


Mental health practitioners may have varying levels of skepticism about the implementation of artificial intelligence (AI) in their practice. For example, when presented with AI-generated feedback regarding diagnostic or treatment decisions, practitioners may be cautious and take steps to ensure accuracy. At the same time, they may be open to incorporating AI-generated feedback into certain aspects of their therapeutic sessions to enhance the quality and effectiveness of care. Although research has begun to examine practitioners' acceptance of AI-enabled tools, there is a lack of specificity, limiting the ability to use the current research to inform practice. This study seeks to address this caveat by examining the intention to use two specific mental health tools: a psychotherapy feedback tool and a treatment recommendation tool. The psychotherapy feedback tool is an AI system that is currently used to analyze data from therapist-patient conversations and provide performance-specific feedback for the therapist, in order to improve motivational interviewing [@cummins_etal19; @hirsch_etal18; @tanana_etal19a; @imel_etal19]. Similarly, the treatment recommendation tool uses voice recordings and mood scores to generate recommendations for psychotherapeutic support [@huang_etal18].


This study builds upon and expands previous research regarding the intention to use AI-enabled mental health tools in four major ways. Firstly, we assess the predictors of an individual's intention to use two specific mental health tools to potentially uncover factors related to the acceptance of tools characterized by specific technological features and designated for certain use cases. Secondly, based on previous findings, we extend the original UTAUT model by considering trust, specific understanding of the tools, and general AI knowledge as predictors of students' intention to use the tools in their future jobs [@arfi_etal21; @gado_etal22]. Thirdly, we test the research model among a sample of psychology masters's students and psychotherapists in training, increasing the practical relevance of the findings. This is because, unlike established psychotherapists, psychology students are required to complete in-depth training to become psychotherapists. Hence, the current research findings may provide useful starting points for incorporating elements into study curricula and psychotherapy training which enhance students' intention to use AI-enabled tools in their future jobs. Finally, we utilize regularized structural equation modeling (RegSEM) to study our research model. Multicollinearity and associated suppression effects are frequently reported in studies investigating multiple UTAUT predictors at once [e.g., @bu_etal21; @chimborazo-azogue_etal21; @yoo_etal15]. RegSEM can offer more reliable estimates and higher statistical power than non-regularized structural equation models, thus potentially overcoming issues associated with multicollinearity [@friemelt_etal22; @scharf_etal21]. In the following, we provide a brief description of the two tools investigated in this research, before introducing the research model.   

# The AI-enabled feedback tool

The provision of supervision and performance feedback on psychotherapy sessions supports trainees' skills acquisition and retention [@tanana_etal19, @moyers_etal05; @helgeronnestad_ladany06]. However, providing ongoing feedback is labor and cost intensive and thus rarely used in training and clinical practice. Often, feedback is based on trainees' self-reports and is only available after the therapy session has concluded [@tanana_etal19]. AI technology may help reduce this problem by providing continuous, immediate, and performance-specific feedback to psychotherapists and trainees. For example, _TIM_ (Therapy Insights Model) uses real-time chat messages exchanged between therapists and patients to provide feedback on topics covered in the session and those which should be addressed in the following session [@cummins_etal19]. _CORE-MI_ (Counselor Observer Ratings Expert for Motivational Interviewing) uses audio recordings of motivational interviewing (MI)^[A counseling method to enhance a patient's motivation to change.] sessions to generate feedback on psychotherapists' adherence to MI principles. This includes six summary measures of MI fidelity: empathy, MI spirit, reflection-to-question ratio, percent open questions, percent complex reflections, and percent MI adherence. A visual summary of the counseling sessions is also included, based on the fidelity assessment, which may be used to inform improvement [@hirsch_etal18]. The tool chosen for the current study was developed based on _CORE-MI_. Participants are presented with information on how speech data recorded during a psychotherapy session is processed and analyzed using ML models to generate feedback for psychotherapists regarding their adherence to MI principles and possibilities for improvement, as shown in @fig-feedback.



```{r, fig.width = 12}
#| include: true
#| label: fig-feedback
#| fig-cap: The output slide of the AI-enabled feedback tool 

library(tiff)
library(grid)
grid.raster(readTIFF("Figures/feedback.tiff"))
```

# The AI-enabled treatment recommendation

Multiple studies have demonstrated the effectiveness of AI-enabled emotion analysis in assessing patients' depressive states and recommending timely intervention, thus advancing mental healthcare [@jan_etal18; @huang_etal18]. In particular, systems that monitor or assess the mood of individuals with mental disorders, such as major depressive disorder (MDD) or bipolar disorder, using speech data have been developed over the past years [@karam_etal17; @khan_etal16]. These systems usually involve the patient recording voice samples through an application installed on their mobile phone, followed by the automated speech data classifier analyzing the data to assess the patient's current mood [@karam_etal17]. The generated mood score can then be used by mental health practitioners to decide whether urgent intervention is needed, particularly as patients with MDD hold a 40% risk of non-fatal lifetime suicide attempts [@sokero_etal05]. Timely psychotherapeutic support may lower the risk of aggravation of depressive symptoms and suicidality [@calati_courtet16]. An example of such a tool is the one developed by _SondeHealth_, which requests the patient to record a voice message answering a predetermined question using their mobile phone, and uses the voice data in a machine learning (ML) model to generate a mood score. Psychotherapists may use the mood score information to decide whether emergency intervention is necessary and whether a patient needs to be given preference in treatment [@sondehealth.com]. The tool chosen for the current study is based on the tool developed by _SondeHealth_. Participants are presented with information on how voice data recorded on a mobile device is processed and analyzed using ML models to generate a mood score that may be used for treatment-related decisions, as shown in @fig-depression. 


```{r, fig.width = 12}
#| include: true
#| label: fig-depression
#| fig-cap: The output slide of the AI-enabled feedback tool 

library(tiff)
library(grid)
grid.raster(readTIFF("Figures/depression.tiff"))
```


# Research model and hypotheses development

The first goal of the current research is to test the applicability of a modified version of the UTAUT in the mental health context to understand the factors that influence the intention to use two specific AI-enabled mental healthcare tools [@gado_etal22; @venkatesh22; @venkatesh_etal03; @venkatesh_etal16]. 
In line with the UTAUT, we propose tool-specific performance expectancy (i.e., the degree to which an individual believes that using a system will enhance their performance) and effort expectancy (i.e., the degree of ease associated with using the technology) to predict the behavioral intention to use the two tools in their future jobs. 

*Hypothesis 1*: There is a positive relationship between perceived performance expectancy and the intention to use the tools in psychotherapy. 

*Hypothesis 2*: There is a positive relationship between perceived effort expectancy and the intention to use the tools in psychotherapy. 

In contrast to experienced psychotherapists, psychology students and psychotherapists in training may be less likely to be influenced by established habits or work procedures which could impede the adoption of new artificial intelligence (AI) technologies [@venkatesh_etal16]. It has been suggested that students are more likely to be affected by their peers and the values and standards of their potential employers [@owusu_etal22]. As a result, we propose that the UTUAT (Unified Theory of Use and Acceptance of Technology) variable, 'social influence' (i.e., the perception that significant others think the system should be used), should be considered a predictor of students' intention to use the feedback tool.

*Hypothesis 3*: There is a positive relationship between social influence and the intention to use the tool in psychotherapy. 

It has been suggested that trust may be a relevant predictor of the intention to use a technology if the level of risk associated with it is high [@arfi_etal21]. This is particularly relevant for the treatment recommendation tool in this study, given the critical nature of the recommendations in comparison to the feedback tool. Thus, we hypothesize that trust may be a predictor of students' intention to use the tools, and that levels of trust and the relationship between trust and the intention to use the tool may differ between the two tools. 

*Hypothesis 4*: There is a positive relationship between trust in the tools and the intention to use them in psychotherapy. 

*Exploratory Hypothesis 4*: a) The level of trust in the treatment recommendation tool will be lower than the level of trust in the feedback tool, and b) the relationship between trust and the intention to use the tool will be stronger for the treatment recommendation tool than for the feedback tool. 

A lack of understanding of the underlying mechanisms of AI-enabled tools in mental healthcare has led to skepticism of their use [@aafjes-vandoorn_etal21; @chekroud_etal21]. In particular, the black box problem of AI-based recommendations has impeded adoption of such tools in mental healthcare due to the importance of transparency and explainability of clinical decision-making [@aafjes-vandoorn_etal21; @chekroud_etal21; @kelly_etal19]. Building on the New Framework for Theorizing and Evaluating Nonadoption, Abandonment, and Challenges to the Scale-Up, Spread, and Sustainability of Health and Care Technologies [NASSS, @greenhalgh_etal17], we propose that knowledge of the technology is a predictor of its perceived demand-side value. We suggest that students who possess the knowledge and skills to apply the tools and understand how the recommendations are derived are more likely to perceive them as useful and may be better equipped to address ethical concerns [@seufert_etal21; @gado_etal22]. To test this, we extend the UTAUT model by including cognitive technology readiness as an indicator of general AI knowledge and specific understanding of the tool as an indicator of specific AI knowledge as predictors of performance expectancy, effort expectancy, and trust. We pre-registered two research questions to test this relationship and tehrefore propose the following two matching exploratory hypotheses:

*Exploratory Hypothesis 5*: The positive relationship between cognitive technology readiness and the intention to use the tools is mediated through a) performance expectancy, b) effort expectancy, and c) trust in the tools. 

*Exploratory Hypothesis 6*: The positive relationship between specific understanding of the tools and the intention to use the tools is mediated through a) performance expectancy, b) effort expectancy, and c) trust in the tools. 


# Methods

```{r read_data}
## Read in data
library("readxl")
library(tidyverse)
data_prolific <- read_excel("../../data/Student_quest/data_prolific.xlsx", col_names = T) %>% .[-1, ] %>% data.frame(.)
data_prolific$source <- 2
data <- read_excel("../../data/Student_quest/data.xlsx", col_names = T) %>% .[-1, ] %>% data.frame(.)
data$source <- 1
source("../../R/custom-functions.R")
```

```{r}
library(gtools)
data_all <- smartbind(data_prolific, data)
```

```{r}
library(dplyr)
## Started answering
data_all <- data_all[!(data_all$Prolific_ID %in% "ggg"), ]

## Remove because not answers on behavioral intention
vars <- data_all %>% select(matches("Beh_Int")) %>% names(.)
data_all_behav <- data_all %>% drop_na(any_of(vars))

percent <- 100-round(nrow(data_all_behav)/ nrow(data_all)*100,2)

## Attention checks
data_all_att <- data_all_behav %>% rename(
  att_1 = gattAI1_7,
  att_2 = learn_anx_3,
  att_3 = dapriv1_5,
  att_4 = SocInf2_4
)

## create attention fails df 
att_1_fail <- data_all_att[(data_all_att$att_1 %in% c("1.0", "3.0", "4.0", "5.0")), ]
att_2_fail <- data_all_att[(data_all_att$att_2 %in% c("1.0", "2.0", "3.0", "4.0", "5.0", "7.0")), ]
att_3_fail <- data_all_att[(data_all_att$att_3 %in% c("1.0", "2.0", "4.0", "5.0", "6.0", "7.0")), ]
att_4_fail <- data_all_att[(data_all_att$att_4 %in% c("1.0", "2.0", "3.0", "4.0")), ]


(attention_fail <- rbind(att_1_fail, att_2_fail, att_3_fail, att_4_fail) %>%
  as_tibble(.)) 

(ID_vals <- data.frame(table(attention_fail$ResponseId)))

(Rows_fails <- attention_fail$ResponseId %in% ID_vals[ID_vals$Freq > 2,1])

(Att_fails <- attention_fail[Rows_fails,])

(data.frame(table(Att_fails$ResponseId)))

## exclude attention fails (more than two fails)
data_all_noatt <- data_all_att[!(data_all_att$ResponseId %in% Att_fails$ResponseId),]

```
##  Participants

Psychology students and psychotherapists were recruited online through social media postings and contacts with administrative offices of universities and psychotherapy training centers. In addition, Prolific, a professional research-focused panel company was commissioned to recruit participants online. The data was collected from October 2022 until January 2023. In total, `r nrow(data_all)` individuals started answering the questionnaire. Of those, `r nrow(data_all_behav)` provided answers on the behavioral intention to use the tools (`r percent`% dropout rate). Finally, `r `nrow(data_all_behav) - nrow(data_all_noatt)` participants failed at least two of the four attention check items [@Oppenheimer2009], leaving us with a final sample size of `r nrow(data_all_noatt)`. 

```{r}
#| include: false

# Gender distribution
male <- unname(table(data_all_noatt$Gender)[1])
male_per <- round(unname(prop.table(table(data_all_noatt$Gender))[1])*100,2)

female <- unname(table(data_all_noatt$Gender)[2])
female_per <- round(unname(prop.table(table(data_all_noatt$Gender))[2])*100,2)

non <- unname(table(data_all_noatt$Gender)[3])
non_per <- round(unname(prop.table(table(data_all_noatt$Gender))[3])*100,2)

# Age distribution
data_all_noatt$Age <- as.numeric(data_all_noatt$Age)


# Study country distribution
data_all_noatt$country <- as.numeric(data_all_noatt$country)

data_all_noatt$country[data_all_noatt$country_3_TEXT == "USA and UK"] <- 2

data_all_noatt$country[data_all_noatt$country_3_TEXT == "UK"] <- 4
data_all_noatt$country[data_all_noatt$country_3_TEXT == "England"] <- 4
data_all_noatt$country[data_all_noatt$country_3_TEXT == "Uk"] <- 4
data_all_noatt$country[data_all_noatt$country_3_TEXT == "United Kingdom"] <- 4
data_all_noatt$country[data_all_noatt$country_3_TEXT == "UK - England"] <- 4

data_all_noatt$country[data_all_noatt$country_3_TEXT == "Canada"] <- 5

table(data_all_noatt$country)

germany <- unname(table(data_all_noatt$country)[1])
germany_per <- round(unname(prop.table(table(data_all_noatt$country))[1])*100,2)

uk <- unname(table(data_all_noatt$country)[4])
uk_per <- round(unname(prop.table(table(data_all_noatt$country))[4])*100,2)


us <- unname(table(data_all_noatt$country)[2])
us_per <- round(unname(prop.table(table(data_all_noatt$country))[2])*100,2)


canada <- unname(table(data_all_noatt$country)[5])
canada_per <- round(unname(prop.table(table(data_all_noatt$country))[5])*100,2)

other <- unname(table(data_all_noatt$country)[3])
other_per <- round(unname(prop.table(table(data_all_noatt$country))[3])*100,2)

# masters focus
data_all_noatt$masters <- as.numeric(data_all_noatt$masters)
table(data_all_noatt$masters, useNA = "always")

clinical <- unname(table(data_all_noatt$masters)[2])
clinical_per <- round(unname(prop.table(table(data_all_noatt$masters))[2])*100,2)

general <- unname(table(data_all_noatt$masters)[1])
general_per <- round(unname(prop.table(table(data_all_noatt$masters))[1])*100,2)

other <- unname(table(data_all_noatt$masters)[3])
other_per <- round(unname(prop.table(table(data_all_noatt$masters))[3])*100,2)

notav <- unname(table(data_all_noatt$masters)[4])
notav_per <- round(unname(prop.table(table(data_all_noatt$masters))[4])*100,2)
```

Of the final sample, *n* = `r male` (`r male_per`%) were male,  *n* = `r female` (`r female_per`%) were female, and `r non` (`r non_per`%) non-binary defined. Participants' age ranged from `r range(data_all_noatt$Age)[1]` to `r range(data_all_noatt$Age)[2]`, with a mean age of `r round(mean(data_all_noatt$Age),2)` years (*SD* = `r round(sd(data_all_noatt$Age),2)`. Most participants (*n* = `r germany`,  `r germany_per`) studied in Germany, *n* = `r uk` (`r uk_per`) in the UK, *n* = `r us` (`r us_per`) in the USA, *n* = `r canada` (`r canada_per`) in Canada, and *n* = `r other` (`r other_per`) elsewhere. Most participants (*n* = `r clinical`, `r clinical_per`%) indicated that their studies were focused on clinical psychology, *n* = `r general` (`r general_per`%) indicated that they studied psychology with no specific focus, and *n* = `r notav` (`r notav_per`%) did not provide this information. 

```{r}
#| include: false
#ge back original data frame name
data_all <- data_all_noatt
```


```{r}
#| include: false
## Rename and recode
## rename
names(data_all) <- gsub("d2priv", "dapriv2", names(data_all))
  
data_num <- data_all %>% 
  select(-matches("Prolific_ID|knowAI3|knowAI6|under4|country|masters_3_TEXT|degree|email|Date|IBA|Progress|Duration|Finished|ResponseI|Recipient|Reference|LocationLat|LocationLon|Channel|UserL|consent")) %>%
  mutate_if(is.character, as.numeric)

data_char <- data_all %>% 
  select(matches("Prolific_ID|knowAI3|knowAI6|under4|country|masters_3_TEXT|degree|email"))

data_all <- cbind(data_num, data_char)

data_all %>% filter_at(vars(d1under1,d1under2),all_vars(is.na(.)))

## create lack of understanding variable
data_all <- data_all %>% 
   mutate(lackunder1 = 
            case_when(
              d1under1 == 1 | d1under2 == 1 ~ 1,
              d1under1 == 2 | d1under2 == 2 ~ 2))


## recode
recode_5 <- function(x) {               
  x * (-1)+6
}
recode_8 <- function(x) {               
  x * (-1)+9
}

data_recode_5 <- apply(select(data_all, matches("gattAI1_3|gattAI1_6|gattAI1_8|gattAI1_9|gattAI1_10|gattAI2_5|gattAI2_9|gattAI2_10")), 2, recode_5)   

data_all[ , colnames(data_all) %in% colnames(data_recode_5)] <- data_recode_5

data_recode_8 <- apply(select(data_all, matches("dapriv1_4|dapriv1_6|dapriv1_7|dapriv2_4|dapriv2_5|dapriv2_6")), 2, recode_5)   

data_all[ , colnames(data_all) %in% colnames(data_recode_8)] <- data_recode_8

```

```{r}
#| include: false
## Make composite data frame
library(sjlabelled)

data_comp <- data_all %>% select(matches("gatt|cog_read|vision|ethic|_anx|techblind|PerfExp|EffExp|SocInf|FacCond|attitude|Beh_Int|anxty|self_eff|priv|trust")) %>% mutate_if(is.character, as.numeric)


demos <- data_all %>% select(matches("under1|under2|under3|knowAI1|knowAI2|knowAI4|knowAI5|knowAI7|^Age$|Gender|^country$|commitment")) %>%  mutate_if(is.character, as.numeric)
text_data <- data_all %>% select(matches("country_3_TEXT|uni|master|degree|knowAI3|knowAI6|under4|invite_raffle|invite_follow|email"))

names(data_comp) <- gsub("_read", "read", names(data_comp))
names(data_comp) <- gsub("_anx", "anx", names(data_comp))
names(data_comp) <- gsub("Beh_Int", "BehInt", names(data_comp))
names(data_comp) <- gsub("self_eff", "selfeff", names(data_comp))


comp_split <- data_comp %>% remove_all_labels(.) %>%
  split.default(sub("_.*", "", names(data_comp)))

comp <- purrr::map(comp_split, ~ rowMeans(.x, na.rm=TRUE))
alph <- purrr::map(comp_split, ~ psych::alpha(.x), data = .x) %>%
  purrr::map(~ .x$total)

comp_df <- do.call("cbind", comp) %>% as.data.frame(.) %>%  cbind(., demos) %>% remove_all_labels(.)
alph_df <- do.call("rbind", alph) %>% round(., 2)
```

## Measurement instruments 

### AI-enabled support tools

Participants were presented with slides that explained how recommendations for the AI-enabled feedback tool (henceforth, Tool 1) and the treatment recommendation tool (henceforth, Tool 2) were generated (the slides are available from the first author upon request). Before seeing the slides, participants read the following short introduction: "On the following page, you will be presented with a tool that is used to [*Tool 1*: provide feedback to psychotherapists about what went well and what could be improved in their sessions; *Tool 2*: generate a mood score to rate the severity of patients' depression. The mood score may be used by psychotherapists to decide which patient to treat first if multiple patients seek treatment and there is limited capacity]. Please read the information carefully and try to understand what the tool does and how it may be used in psychotherapy practice/ training. After the presentation, you will be asked a couple of questions about the tool." 

### Independent variables 

```{r}

## Reliabilities

# prolific 
rel_tab <- alph_df %>%
DT::datatable(
    extensions = 'Buttons', 
    options = list(dom = 'Bfrtip', 
                   buttons = c('excel', "csv"),
                   pageLength = 20))

library(psych)
library(GPArotation)

# general knowledge
alpha_cogread <- alph_df["cogread", 1]
omega_cogread <- round(omega(data_all %>% select(matches("cog_read")), 1)$omega.tot, 2)

# tool 1
alpha_beh1 <- alph_df["BehInt1", 1]
omega_beh1 <- round(omega(data_all %>% select(matches("Beh_Int1")), 1)$omega.tot, 2)

alpha_perf1 <- alph_df["PerfExp1", 1]
omega_perf1 <- round(omega(data_all %>% select(matches("PerfExp1")))$omega.tot,2)

alpha_eff1 <- alph_df["EffExp1", 1]
omega_eff1 <- round(omega(data_all %>% select(matches("EffExp1")))$omega.tot,2)

alpha_soc1 <- alph_df["SocInf1", 1]
omega_soc1 <- round(omega(data_all %>% select(matches("SocInf1")))$omega.tot,2)

alpha_tru1 <- alph_df["trust1", 1]
omega_tru1 <- round(omega(data_all %>% select(matches("trust1")))$omega.tot,2)

alpha_dapriv1 <- alph_df["dapriv1", 1]
omega_dapriv1 <- round(omega(data_all %>% select(matches("dapriv1")))$omega.tot,2)

alpha_anxty1 <- alph_df["anxty1", 1]
omega_anxty1 <- round(omega(data_all %>% select(matches("anxty1")))$omega.tot,2)

# tool 2
alpha_beh2 <- alph_df["BehInt2", 1]
omega_beh2 <- round(omega(data_all %>% select(matches("Beh_Int2")), 1)$omega.tot, 2)

alpha_perf2 <- alph_df["PerfExp2", 1]
omega_perf2 <- round(omega(data_all %>% select(matches("PerfExp2")))$omega.tot,2)

alpha_eff2 <- alph_df["EffExp2", 1]
omega_eff2 <- round(omega(data_all %>% select(matches("EffExp2")))$omega.tot,2)

alpha_soc2 <- alph_df["SocInf2", 1]
omega_soc2 <- round(omega(data_all %>% select(matches("SocInf2")))$omega.tot,2)

alpha_tru2 <- alph_df["trust2", 1]
omega_tru2 <- round(omega(data_all %>% select(matches("trust2")))$omega.tot,2)

alpha_dapriv2 <- alph_df["dapriv2", 1]
omega_dapriv2 <- round(omega(data_all %>% select(matches("dapriv2")))$omega.tot,2)

alpha_anxty2 <- alph_df["anxty2", 1]
omega_anxty2 <- round(omega(data_all %>% select(matches("anxty2")))$omega.tot,2)
```


All UTAUT variables were assessed for each tool separately. The introduction for the scales read: "To what extent do you agree or disagree with the following statements regarding the AI-enabled feedback tool?". Answers were provided on a five-point Likert scale with options ranging from *1 = "Strongly disagree"* to *5 = "Strongly agree"*. Performance expectancy, effort expectancy, and social influence were measured with items adapted from @venkatesh_etal03. *Performance expectancy* was assessed with five items (e.g., "using the AI tool would enable me to accomplish tasks more quickly"). Reliabilities are $\alpha_tool1$ = `r alpha_perf1` and $\omega_tool1$ = `r omega_perf1` for the first tool and $\alpha_tool2$ = `r alpha_perf2` and $\omega_tool2$ = `r omega_perf2` for the second tool. *Effort expectancy* was measured with four items (e.g., "my interaction with the AI tool will be clear and understandable"; $\alpha_tool1$ = `r alpha_eff1`, $\omega_tool1$ = `r omega_eff1`; $\alpha_tool2$ = `r alpha_eff2`, $\omega_tool2$ = `r omega_eff2`). *Social influence* was measured with five items (e.g., "in my future job as a psychotherapist, people who are important to me will think that I should use the AI tool"; $\alpha_tool1$ = `r alpha_soc1`, $\omega_tool1$ = `r omega_soc1`; $\alpha_tool2$ = `r alpha_soc2`, $\omega_tool2$ = `r omega_soc2`). Trust was measured with three items adapted from @venkatesh_etal11 (e.g., "the AI tool will provide access to sincere and genuine feedback"; $\alpha_tool1$ = `r alpha_tru1`, $\omega_tool1$ = `r omega_tru1`; $\alpha_tool2$ = `r alpha_tru2`, $\omega_tool2$ = `r omega_tru2`). 

Specific understanding of the AI-enabled tools was assessed with a single item ("Please rate your understanding of the AI-enabled feedback tool"), with answers ranging from *1 = "I don't understand the tool at all"* to *6 = "I understand the tool extremely well"*. Finally, cognitive AI-readiness was operationalized with five items of the cognition factor of the medical artificial intelligence readiness (MAIRS) scale [@karaca_etal21]. The scale measures terminological knowledge about medical artificial intelligence applications. An example item reads: "I can explain how AI systems are trained" ($\alpha$ = `r alpha_cogread`, $\omega$ = `r omega_cogread`). 

  
### Dependent variable

The behavioral intention to use the tools was measured on a five-point Likert scale ranging from *1 = "Strongly disagree"* to *5 = "Strongly agree"* with three items adapted from @venkatesh_etal03 (e.g., "I intend to use the AI tool in my future job as a psychotherapist"; $\alpha_tool1$ = `r alpha_beh1`, $\omega_tool1$ = `r omega_beh1`; $\alpha_tool2$ = `r alpha_beh2`, $\omega_tool2$ = `r omega_beh2`).

### Control variables

Data privacy concerns and AI anxiety as fears and a sense of insecurity regarding AI technology have repeatedly been identified as negative predictors of the intention to use AI technology [e.g., @mishra_etal21, @chai_etal20]. In addition, it has been shown that males have more positive attitudes toward AI technologies than females [e.g., @fietta_etal22]. Finally, some evidence exists for associations of AI acceptance with age [@liang_lee17] and country [@sindermann_etal21]. Accordingly, we included data privacy and security concerns [@brady_etal21, $\alpha_tool1$ = `r alpha_dapriv1`, $\omega_tool1$ = `r omega_dapriv1`; $\alpha_tool2$ = `r alpha_dapriv2`, $\omega_tool2$ = `r omega_dapriv2`], AI anxiety [@venkatesh_etal03, $\alpha_tool1$ = `r alpha_anxty1`, $\omega_tool1$ = `r omega_anxty1`; $\alpha_tool2$ = `r alpha_anxty2`, $\omega_tool2$ = `r omega_anxty2`], gender (1 = not male, 0 = male), age, and study country as control variables. 


# Data analysis

The data was analyzed using *R*. First, we calculated descriptive statistic summaries, including mean values, standard deviations, and correlations between study variables for each tool. Next, we used the *lavaan* package to investigate the fit of the measurement models for the two devices through confirmatory factor analysis. We compared the theoretical measurement models to two more parsimonious alternative models to assess whether the variables included in the two models are sufficiently distinct. 


Second, we used the *lavaan* package for structural equation modeling (SEM) paired t-tests to compare the levels of performance expectancy, effort expectancy, social influence, trust, and specific understanding between the two tools, thus answering *Exploratory Hypothesis 4a*. Third, we used the *regsem* package in *R* [@jacobucci_etal22] to analyze the relationship between the predictor variables and the intention to use the tool to answer hypotheses 1 through 4 and *Exploratory Hypothesis 4b*. Finally, we used the *regsem* package to test the exploratory mediation models [*Hypotheses 5* and *6*, @serang_etal17].

# Results

Table 1 show the correlations between the model variables. 

## Correlations

```{r}
# select only numeric 
comp_df_mum <- comp_df[ , purrr::map_lgl(comp_df, is.numeric)]

comp_df %>%relocate()
  
comp_df_mum_1 <- comp_df %>% select(matches("anxty1|BehInt1|cogread|EffExp1|jobanx|PerfExp1|SocInf1|soctechblind|trust1|knowAI4_1|knowAI7_1|d1under3_1|Age|Gender|country"))

comp_df_mum_2 <- comp_df %>% select(matches("anxty2|BehInt2|cogread|EffExp2|jobanx|PerfExp2|SocInf2|soctechblind|trust2|knowAI4_1|knowAI7_1|d2under3_1|Age|Gender|country"))


cor_tab_1 <- corstars(comp_df_mum_1, removeTriangle = "upper")
cor_tab_2 <- corstars(comp_df_mum_2, removeTriangle = "lower")

cor_tab_1 %>%
  DT::datatable(
    extensions = 'Buttons', 
    options = list(dom = 'Bfrtip', 
                   buttons = c('excel', "csv"),
                   pageLength = 35,
                  lengthMenu = c(20, 20, 20, 20)))

cor_tab_2 %>%
  DT::datatable(
    extensions = 'Buttons', 
    options = list(dom = 'Bfrtip', 
                   buttons = c('excel', "csv"),
                   pageLength = 35,
                  lengthMenu = c(20, 20, 20, 20)))

```

```{r}
write.table(cor_tab_1, file = "Tables/cors_1.txt", sep = ",", quote = FALSE, row.names = T)

write.table(cor_tab_2, file = "Tables/cors_2.txt", sep = ",", quote = FALSE, row.names = T)

cor_tab_1[upper.tri(cor_tab_1)] <- cor_tab_2[upper.tri(cor_tab_2)]

write.table(cor_tab_1, file = "Tables/cors.txt", sep = ",", quote = FALSE, row.names = T)
```


```{r}
model_full <- '
gatt =~ gattAI1_1 + gattAI1_2 + gattAI1_3 + gattAI1_4 + gattAI1_5 + gattAI1_6 + gattAI1_8 + 
            gattAI1_9 + gattAI1_10 + gattAI1_11 + gattAI2_1 + gattAI2_2 + gattAI2_3 + gattAI2_4 + 
            gattAI2_5 + gattAI2_6 + gattAI2_7 + gattAI2_8 + gattAI2_9 + gattAI2_10
'

model_fit <- lavaan::cfa(model_full, data=data_all, missing = "fiml")
cfa_gatt <- summary(model_fit, standardized=TRUE, fit = TRUE)
cfa_gatt
```

## CFA

```{r}
library(lavaan)

# GENERAL UNDERSTANDING:
# cogread = general understanding of AI (visionread, ethicread)

# SPECIFIC UNDERSTANDING:
# d1under1 = 1 
# d1under2 = 1 
# d1under3 = understanding of the feedback tool

# PERFORMANCE EXPECTANCY 
# PerfExp1

# EFFORT EXPECTANCY 
# EffExp1

# SOCIAL INFLUENCE
# SocInf1

# TRUST
# trust1

# BEHAVIORAL INTENTION 
# BehInt 

# CONTROLS: 
# knowAI7 (stats knowledge)
# knowAI4 (AI knowledge)
# job_anx
# soctechblind
# Age
# Gender
# Country 

```

### Tool 1
```{r}

model_full <- '
cogread =~ cog_read_1 + cog_read_2 + cog_read_3 + cog_read_4 + cog_read_5

PerfExp1 =~ PerfExp1_1 + PerfExp1_2 + PerfExp1_3 + PerfExp1_4 + PerfExp1_5
EffExp1 =~ EffExp1_1 + EffExp1_2 + EffExp1_3 + EffExp1_4
SocInf1 =~ SocInf1_1 + SocInf1_2 + SocInf1_3 + SocInf1_4 + SocInf1_5
Trust1 =~ trust1_1 + trust1_2 + trust1_3
d1under  =~ d1under3_1
BehInt1 =~ Beh_Int1_1 + Beh_Int1_2 + Beh_Int1_3

# controls
job_anx =~ job_anx_1 + job_anx_2 + job_anx_3 + job_anx_4 + job_anx_5 + job_anx_6

soctechblind =~ soctechblind_1 + soctechblind_2 + soctechblind_3 + soctechblind_4

d1under3_1 ~~ 0*d1under3_1
'

model_fit <- lavaan::cfa(model_full, data=data_all_noma, missing = "fiml")
cfa_tool1 <- summary(model_fit, standardized=TRUE, fit = TRUE)
cfa_tool1

write.table(cfa_tool1$fit, file = "Tables/fit_1.txt", sep = ",", quote = FALSE, row.names = T)
```



```{r}
#### PE + EU
model_PEEU <- '
cogread =~ cog_read_1 + cog_read_2 + cog_read_3 + cog_read_4 + cog_read_5

PerfExp1 =~ PerfExp1_1 + PerfExp1_2 + PerfExp1_3 + PerfExp1_4 + PerfExp1_5 + EffExp1_1 + EffExp1_2 + EffExp1_3 + EffExp1_4
SocInf1 =~ SocInf1_1 + SocInf1_2 + SocInf1_3 + SocInf1_4 + SocInf1_5
Trust1 =~ trust1_1 + trust1_2 + trust1_3
d1under  =~ d1under3_1
BehInt1 =~ Beh_Int1_1 + Beh_Int1_2 + Beh_Int1_3

# controls
job_anx =~ job_anx_1 + job_anx_2 + job_anx_3 + job_anx_4 + job_anx_5 + job_anx_6

soctechblind =~ soctechblind_1 + soctechblind_2 + soctechblind_3 + soctechblind_4

d1under3_1 ~~ 0*d1under3_1
'

model_fit_PEEU <- cfa(model_PEEU, data=data_all_noma, missing = "fiml")
summary(model_fit_PEEU, standardized=TRUE, fit = TRUE)
```



```{r}
#### Specific + General
model_SG <- '
cogread =~ cog_read_1 + cog_read_2 + cog_read_3 + cog_read_4 + cog_read_5 + d1under3_1

PerfExp1 =~ PerfExp1_1 + PerfExp1_2 + PerfExp1_3 + PerfExp1_4 + PerfExp1_5
EffExp1 =~ EffExp1_1 + EffExp1_2 + EffExp1_3 + EffExp1_4
SocInf1 =~ SocInf1_1 + SocInf1_2 + SocInf1_3 + SocInf1_4 + SocInf1_5
Trust1 =~ trust1_1 + trust1_2 + trust1_3
BehInt1 =~ Beh_Int1_1 + Beh_Int1_2 + Beh_Int1_3

# controls
job_anx =~ job_anx_1 + job_anx_2 + job_anx_3 + job_anx_4 + job_anx_5 + job_anx_6

soctechblind =~ soctechblind_1 + soctechblind_2 + soctechblind_3 + soctechblind_4

'

model_fit_SG <- cfa(model_SG, data=data_all, missing = "fiml")
summary(model_fit_SG, standardized=TRUE, fit = TRUE)
```

### Tool 2

```{r}
model_full <- '
cogread =~ cog_read_1 + cog_read_2 + cog_read_3 + cog_read_4 + cog_read_5

PerfExp2 =~ PerfExp2_1 + PerfExp2_2 + PerfExp2_3 + PerfExp2_4 + PerfExp2_5
EffExp2 =~ EffExp2_1 + EffExp2_2 + EffExp2_3 + EffExp2_4 
SocInf2 =~ SocInf2_1 + SocInf2_2 + SocInf2_3 + SocInf2_5 + SocInf2_6
Trust2 =~ trust2_1 + trust2_2 + trust2_3
d2under  =~ d2under3_1
BehInt2 =~ Beh_Int2_1 + Beh_Int2_2 + Beh_Int2_3

# controls
job_anx =~ job_anx_1 + job_anx_2 + job_anx_3 + job_anx_4 + job_anx_5 + job_anx_6

soctechblind =~ soctechblind_1 + soctechblind_2 + soctechblind_3 + soctechblind_4

d2under3_1 ~~ 0*d2under3_1
'

model_fit <- cfa(model_full, data=data_all_noma, missing = "fiml")

cfa_tool2 <- summary(model_fit, standardized=TRUE, fit = TRUE)
cfa_tool2

write.table(cfa_tool1$fit, file = "Tables/fit_2.txt", sep = ",", quote = FALSE, row.names = T)
```



```{r}
#### PE + EU
model_PEEU <- '
cogread =~ cog_read_1 + cog_read_2 + cog_read_3 + cog_read_4 + cog_read_5

PerfExp2 =~ PerfExp2_1 + PerfExp2_2 + PerfExp2_3 + PerfExp2_4 + PerfExp2_5 + EffExp2_1 + EffExp2_2 + EffExp2_3 + EffExp2_4 
SocInf2 =~ SocInf2_1 + SocInf2_2 + SocInf2_3 + SocInf2_5 + SocInf2_6
Trust2 =~ trust2_1 + trust2_2 + trust2_3
d2under  =~ d2under3_1
BehInt2 =~ Beh_Int2_1 + Beh_Int2_2 + Beh_Int2_3

# controls
job_anx =~ job_anx_1 + job_anx_2 + job_anx_3 + job_anx_4 + job_anx_5 + job_anx_6

soctechblind =~ soctechblind_1 + soctechblind_2 + soctechblind_3 + soctechblind_4

d2under3_1 ~~ 0*d2under3_1
'

model_fit_PEEU <- cfa(model_PEEU, data=data_all, missing = "fiml")
summary(model_fit_PEEU, standardized=TRUE, fit = TRUE)
```



```{r}
library(lavaan)
#### Specific + General
model_SG <- '
cogread =~ cog_read_1 + cog_read_2 + cog_read_3 + cog_read_4 + cog_read_5 + d2under3_1

PerfExp2 =~ PerfExp2_1 + PerfExp2_2 + PerfExp2_3 + PerfExp2_4 + PerfExp2_5
EffExp2 =~ EffExp2_1 + EffExp2_2 + EffExp2_3 + EffExp2_4 
SocInf2 =~ SocInf2_1 + SocInf2_2 + SocInf2_3 + SocInf2_5 + SocInf2_6
Trust2 =~ trust2_1 + trust2_2 + trust2_3
BehInt2 =~ Beh_Int2_1 + Beh_Int2_2 + Beh_Int2_3

# controls
job_anx =~ job_anx_1 + job_anx_2 + job_anx_3 + job_anx_4 + job_anx_5 + job_anx_6

soctechblind =~ soctechblind_1 + soctechblind_2 + soctechblind_3 + soctechblind_4
'

model_fit_SG <- cfa(model_SG, data=data_all, missing = "fiml")
summary(model_fit_SG, standardized=TRUE, fit = TRUE)
```

## Hypotheses tests 

### Mean comparisons

```{r}
#| include: true
model.1 <- '
PerfExp1 ~~ PerfExp2
PerfExp1 ~~ PerfExp1
PerfExp2 ~~ PerfExp2

PerfExp1 ~ m_PerfExp1 * 1
PerfExp2 ~ m_PerfExp2 * 1

diff := m_PerfExp1 - m_PerfExp2
'
fit.1 <- lavaan::sem(model.1, data=comp_df)
summary(fit.1)
```

```{r}
#| include: true
model.1 <- '
EffExp1 ~~ EffExp2
EffExp1 ~~ EffExp1
EffExp2 ~~ EffExp2

EffExp1 ~ m_EffExp1 * 1
EffExp2 ~ m_EffExp2 * 1

diff := m_EffExp1 - m_EffExp2
'
fit.1 <- lavaan::sem(model.1, data=comp_df)
summary(fit.1)
```

```{r}
#| include: true
model.1 <- '
SocInf1 ~~ SocInf2
SocInf1 ~~ SocInf1
SocInf2 ~~ SocInf2

SocInf1 ~ m_SocInf1 * 1
SocInf2 ~ m_SocInf2 * 1

diff := m_SocInf1 - m_SocInf2
'
fit.1 <- lavaan::sem(model.1, data=comp_df)
summary(fit.1)
```

```{r}
#| include: true
model.1 <- '
d1under1 ~~ d2under1
d1under1 ~~ d1under1
d2under1 ~~ d2under1

d1under1 ~ m_d1under1 * 1
d2under1 ~ m_d2under1 * 1

diff := m_d1under1 - m_d2under1
'
fit.1 <- lavaan::sem(model.1, data=comp_df)
summary(fit.1)
```


```{r}
#| include: true
model.1 <- '
BehInt1 ~~ BehInt2
BehInt1 ~~ BehInt1
BehInt2 ~~ BehInt2

BehInt1 ~ m_BehInt1 * 1
BehInt2 ~ m_BehInt2 * 1

diff := m_BehInt1 - m_BehInt2
'
fit.1 <- lavaan::sem(model.1, data=comp_df)
summary(fit.1)
```


```{r}
model_hypo <- '
cogread =~ cog_read_1 + cog_read_2 + cog_read_3 + cog_read_4 + cog_read_5

PerfExp1 =~ PerfExp1_1 + PerfExp1_2 + PerfExp1_3 + PerfExp1_4 + PerfExp1_5
EffExp1 =~ EffExp1_1 + EffExp1_2 + EffExp1_3 + EffExp1_4
SocInf1 =~ SocInf1_1 + SocInf1_2 + SocInf1_3 + SocInf1_4 + SocInf1_5
Trust1 =~ trust1_1 + trust1_2 + trust1_3
d1under  =~ d1under3_1
BehInt1 =~ Beh_Int1_1 + Beh_Int1_2 + Beh_Int1_3


PerfExp2 =~ PerfExp2_1 + PerfExp2_2 + PerfExp2_3 + PerfExp2_4 + PerfExp2_5
EffExp2 =~ EffExp2_1 + EffExp2_2 + EffExp2_3 + EffExp2_4 
SocInf2 =~ SocInf2_1 + SocInf2_2 + SocInf2_3 + SocInf2_5 + SocInf2_6
Trust2 =~ trust2_1 + trust2_2 + trust2_3
d2under  =~ d2under3_1
BehInt2 =~ Beh_Int2_1 + Beh_Int2_2 + Beh_Int2_3

# controls
job_anx =~ job_anx_1 + job_anx_2 + job_anx_3 + job_anx_4 + job_anx_5 + job_anx_6
soctechblind =~ soctechblind_1 + soctechblind_2 + soctechblind_3 + soctechblind_4

d1under3_1 ~~ 0*d1under3_1
d2under3_1 ~~ 0*d2under3_1

BehInt1 ~ p1*PerfExp1 + e1*EffExp1 + s1*SocInf1 + t1*Trust1 + 
          cj1*job_anx + cs1*soctechblind + ck11* knowAI4_1 + ck21*knowAI7_1 + ca1*Age + cg1*Gender +
          cc1*country
          
BehInt2 ~ p2*PerfExp2 + e2*EffExp2 + s2*SocInf2 + t2*Trust2 + 
          cj2*job_anx + cs2*soctechblind + k12* knowAI4_1 + ck22*knowAI7_1 + ca2*Age + cg2*Gender +
          cc2*country
'

model_fit <- cfa(model_hypo, data=data_all, missing = "fiml")
summary(model_fit, standardized=TRUE, fit = TRUE)
```

### RegSEM

```{r}
#| include: true
library(ISLR)
library(regsem) # we recommend using version 0.50 or later

#lavaan model with all mediators
model1 <-
' 
# Tool 1
# cogread =~ cog_read_1 + cog_read_2 + cog_read_3 + cog_read_4 + cog_read_5
# PerfExp1 =~ PerfExp1_1 + PerfExp1_2 + PerfExp1_3 + PerfExp1_4 + PerfExp1_5
# EffExp1 =~ EffExp1_1 + EffExp1_2 + EffExp1_3 + EffExp1_4
# SocInf1 =~ SocInf1_1 + SocInf1_2 + SocInf1_3 + SocInf1_4 + SocInf1_5
# trust1 =~ trust1_1 + trust1_2 + trust1_3
# BehInt1 =~ Beh_Int1_1 + Beh_Int1_2 + Beh_Int1_3
# 
# jobanx =~ job_anx_1 + job_anx_2 + job_anx_3 + job_anx_4 + job_anx_5 + job_anx_6
# soctechblind =~ soctechblind_1 + soctechblind_2 + soctechblind_3 + soctechblind_4

# direct effect
BehInt1 ~ p1*PerfExp1 + e1*EffExp1 + s1*SocInf1 + t1*trust1 + 
          cj1*jobanx + cs1*soctechblind + ck11*knowAI4_1 + ck21*knowAI7_1 + ca1*Age + cg1*Gender +
          cc1*country + cogread + d1under3_1 
 
# Tool 2          
# cogread =~ cog_read_1 + cog_read_2 + cog_read_3 + cog_read_4 + cog_read_5
# PerfExp2 =~ PerfExp2_1 + PerfExp2_2 + PerfExp2_3 + PerfExp2_4 + PerfExp2_5
# EffExp2 =~ EffExp2_1 + EffExp2_2 + EffExp2_3 + EffExp2_4
# SocInf2 =~ SocInf2_1 + SocInf2_2 + SocInf2_3 + SocInf2_4 + SocInf2_5
# trust2 =~ trust2_1 + trust2_2 + trust2_3
# BehInt2 =~ Beh_Int2_1 + Beh_Int2_2 + Beh_Int2_3
# 
# jobanx =~ job_anx_1 + job_anx_2 + job_anx_3 + job_anx_4 + job_anx_5 + job_anx_6
# soctechblind =~ soctechblind_1 + soctechblind_2 + soctechblind_3 + soctechblind_4

# direct effect
BehInt2 ~ p2*PerfExp2 + e2*EffExp2 + s2*SocInf2 + t2*trust2 + 
          cj2*jobanx + cs2*soctechblind + ck12*knowAI4_1 + ck22*knowAI7_1 + ca2*Age + cg2*Gender +
          cc2*country + cogread + d2under3_1 
'
fit.delta = lavaan::sem(model1,data = comp_df)

summary(fit.delta)
```


```{r}
#identify parameter numbers to penalize with pars_pen
options(max.print=1000000)
extractMatrices(fit.delta)$A

#exploratory analysis via regularization
#Stage 1
#find tuning parameter
fit.reg.tune = cv_regsem(model = fit.delta,type = "lasso",fit.ret = c("rmsea", "BIC", "chisq"), n.lambda = 100, jump = 0.005, pars_pen = "regressions", multi.iter = TRUE)
```


```{r}
#| include: true
#find minimum BIC value and associated lambda value
bics = fit.reg.tune[[2]][,"BIC"]
# remove the one that did not converge
bics<- bics[bics >= 0]  


plot(seq(0,0.495,by = 0.005),bics,main = "BIC by lambda",
xlab = "lambda",ylab = "BIC")
plot(fit.reg.tune,show.minimum="BIC")

min.bic = min(bics)
lambda = fit.reg.tune[[2]][which(bics == min.bic),"lambda"]
#fit model with selected value of lambda

fit.reg1 = multi_optim(fit.delta,type = "lasso",lambda = lambda)

result_penal <- summary(fit.reg1)

#names(result_penal$estimates)[result_penal$estimates == 0]
#names(result_penal$estimates)[!result_penal$estimates == 0]

#Stage 2
#refit model with only selected mediators
model2 <-
'# Tool 1
# direct effect
BehInt1 ~ PerfExp1 + 
          EffExp1 + 
          SocInf1 + 
          trust1 + 
          jobanx + 
          soctechblind + 
          cogread 
          #ck11*knowAI4_1 + 
          #ck21*knowAI7_1 + 
          #ca1*Age + 
          #cg1*Gender +
          #cc1*country + 
          #d1under3_1 
 
# Tool 2          
# direct effect
BehInt2 ~ PerfExp2 + 
          SocInf2 +
          trust2 + 
          soctechblind +
          knowAI7_1 + 
          Age +
          country 
          #EffExp2 + 
          #jobanx +  
          #knowAI4_1 + 
          #Gender +
          #cogread 
          #d2under3_1 
'
fit.reg2 = sem(model2,data = comp_df,fixed.x = T)
summary(fit.reg2, fit = T)
```

### RegSEM mediation model

# Appendix

## Model 

```{r}
#| eval: false
library(sem)
#| echo: true
multipleMediation <- '
effort =~ e1 + e2 + e3
perform =~ p1 + p2 + p3
intent =~ i1 + i2 + i3
learn =~ l1 + l2 + l3

intent ~ b1 * perform + b2 * effort + c * learn
perform ~ a1 * learn
effort ~ a2 * learn

indirect1 := a1 * b1
indirect2 := a2 * b2

total := c + (a1 * b1) + (a2 * b2)
perform ~~ effort
'
fit <- sem(model = multipleMediation, data = Data)
summary(fit)
```

## RegSEM

```{r}
#| eval: false
library(ISLR)
library(regsem) # we recommend using version 0.50 or later
data(College)
#select only public schools
College1 = College[which(College$Private == "No"),]
#select and standardize variables of interest
Data = data.frame(scale(College1[c(3,4,9:12,15,17)]))
#lavaan model with all mediators
model1 <-
' # direct effect (c_prime)
Enroll ~ c_prime*Accept
# mediators
#a paths
Outstate ~ a1*Accept
Room.Board ~ a2*Accept
Books ~ a3*Accept
Personal ~ a4*Accept
S.F.Ratio ~ a5*Accept
Expend ~ a6*Accept
#b paths
Enroll ~ b1*Outstate + b2*Room.Board + b3*Books +
b4*Personal + b5*S.F.Ratio + b6*Expend
# indirect effects (a*b)
a1b1: = a1*b1
a2b2: = a2*b2
a3b3: = a3*b3
a4b4: = a4*b4
a5b5: = a5*b5
a6b6: = a6*b6
#total effect (c)
c := c_prime + (a1*b1) + (a2*b2) + (a3*b3) + (a4*b4) +
(a5*b5) + (a6*b6)
'
fit.delta = sem(model1,data = Data,fixed.x = T)
#identify parameter numbers to penalize with pars_pen
extractMatrices(fit.delta)$A
#exploratory mediation analysis via regularization
#Stage 1
#find tuning parameter
fit.reg.tune = cv_regsem(model = fit.delta,type = "enet",
pars_pen = c(2:13),fit.ret = "BIC",n.lambda = 120,lambda.start = 0,jump = 0.005)


fit.reg.tune
#find minimum BIC value and associated lambda value
bics = fit.reg.tune[[2]][,"BIC"]
# remove the one that did not converge
bics<- bics[bics >= 0]  

plot(seq(0,0.590,by = 0.005),bics,main = "BIC by lambda",
xlab = "lambda",ylab = "BIC")

min.bic = min(bics)
lambda = fit.reg.tune[[2]][which(bics == min.bic),"lambda"]
#fit model with selected value of lambda
fit.reg1 = multi_optim(fit.delta,type = "lasso", pars_pen = c(2:13),lambda = lambda,gradFun = "ram",
optMethod = "coord_desc")

summary(fit.reg1)
#display specific indirect effects
fit.reg1$mediation
#Stage 2
#refit model with only selected mediators
model2 <-
' # direct effect (c_prime)
Enroll ~ c_prime*Accept
# mediators
Room.Board ~ a2*Accept
Personal ~ a4*Accept
Expend ~ a6*Accept
Enroll ~ b2*Room.Board + b4*Personal + b6*Expend
# indirect effects (a*b)
a2b2: = a2*b2
a4b4: = a4*b4
a6b6: = a6*b6
#total effect (c)
c := c_prime + (a2*b2) + (a4*b4) + (a6*b6)
'
fit.reg2 = sem(model2,data = Data,fixed.x = T)
summary(fit.reg2)
```


## Discussion 

HERE STH ON WHY UTAUT AND NOT OTHER THEORIES:

- because social influence is included and may be relevant among students 
- we address the criticism of the UTAUT [@shachak_etal19]:

1. Value adding use is often neglected in UTAUT research [@shachak_etal19]; we do not focus on how the AI tool is used in practice. BUT: the prerequisite for value adding use is acceptance and openness towards a technology; by investigating the hypotheses in a student sample and focusing on the intention to use the tool in their future jobs, we shed light on the processes that enable value adding use

2. Adopt and develop theoretical frameworks and methodologies that account for multiple, interrelated, sociotechnical aspects [@shachak_etal19]: Because students are not yet operating in an organizational context, influencing factors are limited to their social contexts and the educational setting; accordingly, our research allows a stronger focus on the individual predictors of the intention to use the tool; without confounding by organizational setting, work tasks, and habits 

3. same applied to "Accounting for health system complexity" [@shachak_etal19]

4. Understanding and reconciling multiple user needs [@shachak_etal19]: We selected a relatively homogenous sample of psychology master's students - reconciliation of multiple user needs does not play a major role 

5. Consider temporal dimensions of HIT implementation [@shachak_etal19]: We do not focus on an implementation setting, but on general openness towards using the tool. 
\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
